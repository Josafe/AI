{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir abastract class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_layer():\n",
    "\n",
    "    def __init__(self, input_dimensions, output_dimensions):\n",
    "        self.w = 2 * np.random.rand(input_dimensions, output_dimensions) - 1 #Genera un array de 1 a -1\n",
    "        self.b = np.zeros((1, output_dimensions))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x @ self.w + self.b #Multiplica les 2 arrays\n",
    "    \n",
    "    def backward(self, error):\n",
    "        keep_prop = 0.25\n",
    "        gamma = 0.003\n",
    "        m = error.shape[0]\n",
    "        #self.dW = self.x.T @ error #Lo mateix que la linea de baix, molt important l'ordre\n",
    "        #self.dW = 1/m * (self.x.T @ error) #Transposem l'error per a multiplicar correctament les matrius (teoria a la llibreta), dW es el valor a canviar a W2\n",
    "        self.dW = np.zeros(self.w.shape) \n",
    "        self.dB = 1/m * error.sum(axis=0)\n",
    "        return (self.w @ error.T).T\n",
    "    \n",
    "    def update_parameters(self, lr):\n",
    "        self.w = self.w - lr * self.dW\n",
    "        self.b = self.b - lr * self.dB\n",
    "\n",
    "x = np.array([[1,0,1,0],[0,1,1,1]])\n",
    "ll1 = linear_layer(4,2)\n",
    "\n",
    "ll1.forward(x)\n",
    "\n",
    "# error = 2* (ypred - yreal)\n",
    "error = np.array([[ 0.07912738,  0.77109688],[ 0.73532997, -0.13105195]])\n",
    "\n",
    "ll1.backward(error)\n",
    "\n",
    "assert ll1.w.shape == ll1.dW.shape\n",
    "\n",
    "ll1.update_parameters(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Definir activation layers and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu_layer():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.Z = np.maximum(0,x)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, error): #L'error es la derivada de ReLu\n",
    "        return error * (self.Z > 0)\n",
    "    \n",
    "    def update_parameters(self, lr):\n",
    "        pass\n",
    "\n",
    "class input_layer():\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "    def backward(self, error):\n",
    "        return error\n",
    "    \n",
    "    def update_parameters(self, lr):\n",
    "        pass\n",
    "\n",
    "class flatten_layer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (bs, 28, 28) -> (bs, 784)\n",
    "        return x.reshape(x.shape[0], x.shape[1] * x.shape[2])\n",
    "    \n",
    "    def backward(self, error):\n",
    "        pass\n",
    "    def update_parameters(self, lr):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m NN_model(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m],[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m---> 31\u001b[0m ypred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[ \u001b[38;5;241m0.07912738\u001b[39m,  \u001b[38;5;241m0.77109688\u001b[39m],[ \u001b[38;5;241m0.73532997\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.13105195\u001b[39m]])\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mbackward(error)\n",
      "Cell \u001b[0;32mIn[93], line 12\u001b[0m, in \u001b[0;36mNN_model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequential: \u001b[38;5;66;03m#Cada layer del self.sequencial\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         x \u001b[38;5;241m=\u001b[39m y \u001b[38;5;66;03m#En la seguent capa la Y es converteix en la X i aixi succesivament.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "Cell \u001b[0;32mIn[92], line 36\u001b[0m, in \u001b[0;36mflatten_layer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# (bs, 28, 28) -> (bs, 784)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "class NN_model():\n",
    "    \n",
    "    def __init__(self, input_layer_dimensions, hidden_layer_dimensions, output_layer_dimensions):\n",
    "        self.sequential = [flatten_layer(),\n",
    "                           input_layer(input_layer_dimensions), #Neurones d'entrada\n",
    "                           linear_layer(input_layer_dimensions, hidden_layer_dimensions), #Redimensionar de 784 a 100\n",
    "                           ReLu_layer(), #ReLu \n",
    "                           linear_layer(hidden_layer_dimensions, output_layer_dimensions)] #Redimensionar de 100 a 10\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.sequential: #Cada layer del self.sequencial\n",
    "            y = layer.forward(x)\n",
    "            x = y #En la seguent capa la Y es converteix en la X i aixi succesivament.\n",
    "        return y\n",
    "    \n",
    "    def backward(self, error):\n",
    "        for layer in reversed(self.sequential): #Voltejem amb reversed ja que al backward va a l'inversa\n",
    "            y = layer.backward(error)\n",
    "            error = y #El mateix que el forward pero a la inversa\n",
    "        return error\n",
    "    \n",
    "    def update_parameters(self, learning_rate = 0.03):\n",
    "        for layer in self.sequential:\n",
    "            layer.update_parameters(learning_rate)\n",
    "        \n",
    "\n",
    "\n",
    "model = NN_model(4,3,2)\n",
    "\n",
    "x = np.array([[1,0,1,0],[0,1,1,1]])\n",
    "ypred = model.forward(x)\n",
    "error = np.array([[ 0.07912738,  0.77109688],[ 0.73532997, -0.13105195]])\n",
    "model.backward(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "\n",
    "    def __init__(self, X, y, batch_size, shuffle = True):\n",
    "        self.bs = batch_size\n",
    "\n",
    "        randomizer = np.arange(len(y))\n",
    "        # np.arange(len(y)) = np.array(range(len(y)))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(randomizer)\n",
    "\n",
    "        self.X = X[randomizer]\n",
    "        self.y = y[randomizer]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]/255, self.y[idx]\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    #idx.convert transforma en array com podras observar a baix\n",
    "X_train = idx2numpy.convert_from_file('Mnist/train-images.idx3-ubyte')\n",
    "y_train = idx2numpy.convert_from_file('Mnist/train-labels.idx1-ubyte')\n",
    "\n",
    "X_test = idx2numpy.convert_from_file('Mnist/t10k-images.idx3-ubyte') \n",
    "y_test = idx2numpy.convert_from_file('Mnist/t10k-labels.idx1-ubyte') \n",
    "    \n",
    "train_dataloader = Dataloader(X_train, y_train, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "prova, y = train_dataloader[5:2000:10]\n",
    "print(prova.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 7 0 6]\n"
     ]
    }
   ],
   "source": [
    "_, y = train_dataloader[0:5]\n",
    "print(y)\n",
    "\n",
    "def one_hot_encoding(y, num_classes):\n",
    "    y_one_hot_encoded = np.zeros((len(y), num_classes))\n",
    "    y_one_hot_encoded[np.arange(len(y)),y] = 1\n",
    "    return y_one_hot_encoded\n",
    "\n",
    "yr = one_hot_encoding(y,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining train steps and test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_model(784, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultat funció de cost:  0.1262632342340465\n"
     ]
    }
   ],
   "source": [
    "def train_step(model, X, y, lr, verbose = True):\n",
    "    # X es un batch de dades\n",
    "\n",
    "    logits = model.forward(X)\n",
    "    yreal = one_hot_encoding(y, 10)\n",
    "    error = -2 * (yreal - logits)\n",
    "    model.backward(error)\n",
    "    model.update_parameters(learning_rate=lr)\n",
    "    cost = np.mean((logits - yreal) ** 2)\n",
    "    if verbose:\n",
    "        print(\"resultat funció de cost: \", cost)\n",
    "\n",
    "def test_step(model, X, y, verbose = True):\n",
    "    logits = model.forward(X)\n",
    "    accuracy = np.sum(np.argmax(logits, axis=1) == y)/len(y)\n",
    "    if verbose:\n",
    "        print(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "X_batch, y_batch = train_dataloader[0:1000]\n",
    "train_step(model, X_batch, y_batch, lr = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultat funció de cost:  0.0899591089534486\n",
      "resultat funció de cost:  0.08998027748094328\n",
      "resultat funció de cost:  0.0899891807711429\n",
      "resultat funció de cost:  0.08994684306920848\n",
      "resultat funció de cost:  0.09001200964043042\n",
      "resultat funció de cost:  0.08989444997834149\n",
      "resultat funció de cost:  0.08989001133004565\n",
      "resultat funció de cost:  0.08999743114356491\n",
      "resultat funció de cost:  0.08995381243264879\n",
      "resultat funció de cost:  0.09000704339847353\n",
      "resultat funció de cost:  0.08999010912552492\n",
      "resultat funció de cost:  0.08996604967583544\n",
      "resultat funció de cost:  0.08997799221622611\n",
      "resultat funció de cost:  0.08994226162501862\n",
      "resultat funció de cost:  0.0899156423687265\n",
      "resultat funció de cost:  0.09001166435447208\n",
      "resultat funció de cost:  0.08999780016313978\n",
      "resultat funció de cost:  0.0899703741907302\n",
      "resultat funció de cost:  0.08997733462899274\n",
      "resultat funció de cost:  0.09000757115633073\n",
      "resultat funció de cost:  0.0899417028396558\n",
      "resultat funció de cost:  0.0899418306870799\n",
      "resultat funció de cost:  0.08990523386362388\n",
      "resultat funció de cost:  0.09002862327871912\n",
      "resultat funció de cost:  0.08999104338905317\n",
      "resultat funció de cost:  0.08998198920846807\n",
      "resultat funció de cost:  0.09005708199058768\n",
      "resultat funció de cost:  0.08991383037178163\n",
      "resultat funció de cost:  0.09000272127328138\n",
      "resultat funció de cost:  0.08999524533398667\n",
      "resultat funció de cost:  0.09077382555482152\n",
      "resultat funció de cost:  0.08991693482494424\n",
      "resultat funció de cost:  0.09004510209869675\n",
      "resultat funció de cost:  0.09005128891884563\n",
      "resultat funció de cost:  0.08991739606217813\n",
      "resultat funció de cost:  0.08996697837177242\n",
      "resultat funció de cost:  0.08996343041098191\n",
      "resultat funció de cost:  0.09001352436597354\n",
      "resultat funció de cost:  0.08995959314820416\n",
      "resultat funció de cost:  0.08999143465918888\n",
      "resultat funció de cost:  0.08999633081690975\n",
      "resultat funció de cost:  0.09003915142031124\n",
      "resultat funció de cost:  0.08995631567518012\n",
      "resultat funció de cost:  0.08994421226526447\n",
      "resultat funció de cost:  0.0899419760671956\n",
      "resultat funció de cost:  0.08991362491028222\n",
      "resultat funció de cost:  0.0903312005432243\n",
      "resultat funció de cost:  0.08998032934996913\n",
      "resultat funció de cost:  0.09013208720047851\n",
      "resultat funció de cost:  0.09003585562568325\n",
      "resultat funció de cost:  0.08994715395636502\n",
      "resultat funció de cost:  0.09006034274071872\n",
      "resultat funció de cost:  0.09005898707894798\n",
      "resultat funció de cost:  0.08997175681086549\n",
      "resultat funció de cost:  0.08997487009599991\n",
      "resultat funció de cost:  0.08997767200041695\n",
      "resultat funció de cost:  0.08989004734487477\n",
      "resultat funció de cost:  0.08997433304784545\n",
      "resultat funció de cost:  0.08995034980733879\n",
      "resultat funció de cost:  0.09002464439856869\n",
      "resultat funció de cost:  0.09003008259269388\n",
      "resultat funció de cost:  0.08993071825186137\n",
      "resultat funció de cost:  0.08990956805319657\n",
      "resultat funció de cost:  0.0899838494702962\n",
      "resultat funció de cost:  0.08997782957832932\n",
      "resultat funció de cost:  0.08997288118001523\n",
      "resultat funció de cost:  0.08994108559981742\n",
      "resultat funció de cost:  0.08996361700919764\n",
      "resultat funció de cost:  0.0899659925008742\n",
      "resultat funció de cost:  0.09002758985250288\n",
      "resultat funció de cost:  0.09001194884872026\n",
      "resultat funció de cost:  0.08995237918166257\n",
      "resultat funció de cost:  0.0899584407391306\n",
      "resultat funció de cost:  0.0900156655910928\n",
      "resultat funció de cost:  0.09000793098607345\n",
      "resultat funció de cost:  0.08984856450713614\n",
      "resultat funció de cost:  0.08995499324429329\n",
      "resultat funció de cost:  0.09001168397305993\n",
      "resultat funció de cost:  0.0899350742660567\n",
      "resultat funció de cost:  0.08993812628468467\n",
      "resultat funció de cost:  0.0900681836523438\n",
      "resultat funció de cost:  0.0900860898399572\n",
      "resultat funció de cost:  0.09000954917104836\n",
      "resultat funció de cost:  0.08999667825990726\n",
      "resultat funció de cost:  0.08997258876171955\n",
      "resultat funció de cost:  0.08993428216358423\n",
      "resultat funció de cost:  0.09000178522358189\n",
      "resultat funció de cost:  0.08996604786887827\n",
      "resultat funció de cost:  0.08991472055591627\n",
      "resultat funció de cost:  0.09000197929744805\n",
      "resultat funció de cost:  0.090019872390008\n",
      "resultat funció de cost:  0.09002791013327088\n",
      "resultat funció de cost:  0.08988103606024503\n",
      "resultat funció de cost:  0.09004919468090557\n",
      "resultat funció de cost:  0.09009076556161624\n",
      "resultat funció de cost:  0.09001445250143882\n",
      "resultat funció de cost:  0.0899679830290171\n",
      "resultat funció de cost:  0.09003047659816117\n",
      "resultat funció de cost:  0.08991847541322927\n",
      "resultat funció de cost:  0.08994950722574295\n",
      "resultat funció de cost:  0.09003053779583424\n",
      "resultat funció de cost:  0.08996041617971948\n",
      "resultat funció de cost:  0.08989241794107293\n",
      "resultat funció de cost:  0.0899574856975347\n",
      "resultat funció de cost:  0.08995917245869993\n",
      "resultat funció de cost:  0.08998700051002403\n",
      "resultat funció de cost:  0.09001623943552416\n",
      "resultat funció de cost:  0.08997697317282653\n",
      "resultat funció de cost:  0.08997186381055063\n",
      "resultat funció de cost:  0.08990642283286986\n",
      "resultat funció de cost:  0.08995134189637442\n",
      "resultat funció de cost:  0.08997029818247143\n",
      "resultat funció de cost:  0.08996783848856871\n",
      "resultat funció de cost:  0.08998589732659798\n",
      "resultat funció de cost:  0.08999904488707368\n",
      "resultat funció de cost:  0.09004809641733555\n",
      "resultat funció de cost:  0.0899412291672893\n",
      "resultat funció de cost:  0.09000154853980182\n",
      "resultat funció de cost:  0.08999323541620706\n",
      "resultat funció de cost:  0.09828233112749782\n"
     ]
    }
   ],
   "source": [
    "def train_loop(model, dataloader, lr, verbose):\n",
    "    for i in np.arange(0, len(dataloader), dataloader.bs):\n",
    "        X_batch, y_batch = dataloader[i:i+dataloader.bs]\n",
    "\n",
    "        train_step(model, X_batch, y_batch, lr, verbose)\n",
    "\n",
    "def test_loop(model, dataloader, verbose):\n",
    "    for i in np.arange(0, len(dataloader), dataloader.bs):\n",
    "        X_batch, y_batch = dataloader[i:i+dataloader.bs]\n",
    "\n",
    "        test_step(model, X_batch, y_batch, verbose)\n",
    "\n",
    "train_loop(model, train_dataloader, 0.03, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(hidden_size = 100, batch_size = 1000, learning_rate = 0.03, epochs = 10, verbose = True):\n",
    "\n",
    "    X_train = idx2numpy.convert_from_file('Mnist/train-images.idx3-ubyte')\n",
    "    y_train = idx2numpy.convert_from_file('Mnist/train-labels.idx1-ubyte')\n",
    "\n",
    "    X_test = idx2numpy.convert_from_file('Mnist/t10k-images.idx3-ubyte') \n",
    "    y_test = idx2numpy.convert_from_file('Mnist/t10k-labels.idx1-ubyte') \n",
    "    \n",
    "    train_dataloader = Dataloader(X_train, y_train, batch_size)\n",
    "    test_dataloader = Dataloader(X_test, y_test, batch_size)\n",
    "    model = NN_model(784, hidden_size, 10)\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loop(model, train_dataloader, learning_rate, verbose)\n",
    "        test_loop(model, test_dataloader,verbose=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.108\n",
      "0.122\n",
      "0.126\n",
      "0.11\n",
      "0.118\n",
      "0.122\n",
      "0.084\n",
      "0.12\n",
      "0.112\n",
      "0.128\n",
      "0.134\n",
      "0.116\n",
      "0.148\n",
      "0.118\n",
      "0.088\n",
      "0.112\n",
      "0.118\n",
      "0.124\n",
      "0.12\n",
      "0.096\n",
      "0.104\n",
      "0.114\n",
      "0.102\n",
      "0.112\n",
      "0.116\n",
      "0.116\n",
      "0.104\n",
      "0.108\n",
      "0.124\n",
      "0.12\n",
      "0.122\n",
      "0.108\n",
      "0.13\n",
      "0.13\n",
      "0.108\n",
      "0.12\n",
      "0.112\n",
      "0.12\n",
      "0.104\n",
      "0.09\n",
      "0.084\n",
      "0.096\n",
      "0.096\n",
      "0.098\n",
      "0.074\n",
      "0.084\n",
      "0.09\n",
      "0.084\n",
      "0.076\n",
      "0.096\n",
      "0.07\n",
      "0.09\n",
      "0.094\n",
      "0.118\n",
      "0.092\n",
      "0.102\n",
      "0.086\n",
      "0.1\n",
      "0.096\n",
      "0.096\n",
      "0.078\n",
      "0.094\n",
      "0.094\n",
      "0.09\n",
      "0.058\n",
      "0.084\n",
      "0.088\n",
      "0.082\n",
      "0.08\n",
      "0.086\n",
      "0.056\n",
      "0.09\n",
      "0.094\n",
      "0.102\n",
      "0.082\n",
      "0.096\n",
      "0.09\n",
      "0.096\n",
      "0.096\n",
      "0.09\n",
      "0.074\n",
      "0.09\n",
      "0.088\n",
      "0.088\n",
      "0.056\n",
      "0.074\n",
      "0.092\n",
      "0.074\n",
      "0.076\n",
      "0.078\n",
      "0.064\n",
      "0.074\n",
      "0.092\n",
      "0.104\n",
      "0.092\n",
      "0.084\n",
      "0.096\n",
      "0.096\n",
      "0.104\n",
      "0.082\n",
      "0.08\n",
      "0.094\n",
      "0.082\n",
      "0.09\n",
      "0.056\n",
      "0.076\n",
      "0.08\n",
      "0.072\n",
      "0.084\n",
      "0.086\n",
      "0.06\n",
      "0.08\n",
      "0.086\n",
      "0.11\n",
      "0.09\n",
      "0.088\n",
      "0.084\n",
      "0.09\n",
      "0.106\n",
      "0.088\n",
      "0.084\n",
      "0.088\n",
      "0.078\n",
      "0.092\n",
      "0.062\n",
      "0.074\n",
      "0.078\n",
      "0.076\n",
      "0.084\n",
      "0.082\n",
      "0.064\n",
      "0.078\n",
      "0.088\n",
      "0.104\n",
      "0.09\n",
      "0.084\n",
      "0.084\n",
      "0.094\n",
      "0.098\n",
      "0.084\n",
      "0.086\n",
      "0.094\n",
      "0.082\n",
      "0.096\n",
      "0.054\n",
      "0.064\n",
      "0.082\n",
      "0.074\n",
      "0.082\n",
      "0.084\n",
      "0.06\n",
      "0.084\n",
      "0.09\n",
      "0.11\n",
      "0.082\n",
      "0.082\n",
      "0.088\n",
      "0.092\n",
      "0.104\n",
      "0.094\n",
      "0.088\n",
      "0.1\n",
      "0.086\n",
      "0.096\n",
      "0.056\n",
      "0.06\n",
      "0.078\n",
      "0.074\n",
      "0.076\n",
      "0.078\n",
      "0.062\n",
      "0.082\n",
      "0.094\n",
      "0.108\n",
      "0.082\n",
      "0.084\n",
      "0.092\n",
      "0.1\n",
      "0.102\n",
      "0.096\n",
      "0.086\n",
      "0.104\n",
      "0.084\n",
      "0.096\n",
      "0.054\n",
      "0.062\n",
      "0.078\n",
      "0.076\n",
      "0.086\n",
      "0.086\n",
      "0.07\n",
      "0.076\n",
      "0.084\n",
      "0.108\n",
      "0.078\n",
      "0.086\n",
      "0.088\n",
      "0.096\n",
      "0.102\n",
      "0.098\n"
     ]
    }
   ],
   "source": [
    "main(hidden_size = 100,\n",
    "     batch_size = 500,\n",
    "     epochs = 10,\n",
    "     verbose = False\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
