{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases del dataset: ['abomasnow', 'abra', 'absol', 'accelgor', 'aegislash-shield', 'aerodactyl', 'aggron', 'aipom', 'alakazam', 'alcremie', 'alomomola', 'altaria', 'amaura', 'ambipom', 'amoonguss', 'ampharos', 'annihilape', 'anorith', 'appletun', 'applin', 'araquanid', 'arbok', 'arboliva', 'arcanine', 'arceus', 'archen', 'archeops', 'arctibax', 'arctovish', 'arctozolt', 'ariados', 'armaldo', 'armarouge', 'aromatisse', 'aron', 'arrokuda', 'articuno', 'audino', 'aurorus', 'avalugg', 'axew', 'azelf', 'azumarill', 'azurill', 'bagon', 'baltoy', 'banette', 'barbaracle', 'barboach', 'barraskewda', 'basculegion-male', 'basculin-red-striped', 'bastiodon', 'baxcalibur', 'bayleef', 'beartic', 'beautifly', 'beedrill', 'beheeyem', 'beldum', 'bellibolt', 'bellossom', 'bellsprout', 'bergmite', 'bewear', 'bibarel', 'bidoof', 'binacle', 'bisharp', 'blacephalon', 'blastoise', 'blaziken', 'blipbug', 'blissey', 'blitzle', 'boldore', 'boltund', 'bombirdier', 'bonsly', 'bouffalant', 'bounsweet', 'braixen', 'brambleghast', 'bramblin', 'braviary', 'breloom', 'brionne', 'bronzong', 'bronzor', 'brute-bonnet', 'bruxish', 'budew', 'buizel', 'bulbasaur', 'buneary', 'bunnelby', 'burmy', 'butterfree', 'buzzwole', 'cacnea', 'cacturne', 'calyrex', 'camerupt', 'capsakid', 'carbink', 'carkol', 'carnivine', 'carracosta', 'carvanha', 'cascoon', 'castform', 'caterpie', 'celebi', 'celesteela', 'centiskorch', 'ceruledge', 'cetitan', 'cetoddle', 'chandelure', 'chansey', 'charcadet', 'charizard', 'charjabug', 'charmander', 'charmeleon', 'chatot', 'cherrim', 'cherubi', 'chesnaught', 'chespin', 'chewtle', 'chikorita', 'chimchar', 'chimecho', 'chinchou', 'chingling', 'cinccino', 'cinderace', 'clamperl', 'clauncher', 'clawitzer', 'claydol', 'clefable', 'clefairy', 'cleffa', 'clobbopus', 'clodsire', 'cloyster', 'coalossal', 'cobalion', 'cofagrigus', 'combee', 'combusken', 'comfey', 'conkeldurr', 'copperajah', 'corphish', 'corsola', 'corviknight', 'corvisquire', 'cosmoem', 'cosmog', 'cottonee', 'crabominable', 'crabrawler', 'cradily', 'cramorant', 'cranidos', 'crawdaunt', 'cresselia', 'croagunk', 'crobat', 'crocalor', 'croconaw', 'crustle', 'cryogonal', 'cubchoo', 'cubone', 'cufant', 'cursola', 'cutiefly', 'cyclizar', 'cyndaquil', 'dachsbun', 'darkrai', 'darmanitan-standard', 'dartrix', 'darumaka', 'decidueye', 'dedenne', 'deerling', 'deino', 'delcatty', 'delibird', 'delphox', 'deoxys-normal', 'dewgong', 'dewott', 'dewpider', 'dhelmise', 'dialga', 'diancie', 'diggersby', 'diglett', 'ditto', 'dodrio', 'doduo', 'dolliv', 'dondozo', 'donphan', 'dottler', 'doublade', 'dracovish', 'dracozolt', 'dragalge', 'dragapult', 'dragonair', 'dragonite', 'drakloak', 'drampa', 'drapion', 'dratini', 'drednaw', 'dreepy', 'drifblim', 'drifloon', 'drilbur', 'drizzile', 'drowzee', 'druddigon', 'dubwool', 'ducklett', 'dudunsparce-two-segment', 'dugtrio', 'dunsparce', 'duosion', 'duraludon', 'durant', 'dusclops', 'dusknoir', 'duskull', 'dustox', 'dwebble', 'eelektrik', 'eelektross', 'eevee', 'eiscue-ice', 'ekans', 'eldegoss', 'electabuzz', 'electivire', 'electrike', 'electrode', 'elekid', 'elgyem', 'emboar', 'emolga', 'empoleon', 'enamorus-incarnate', 'entei', 'escavalier', 'espathra', 'espeon', 'espurr', 'eternatus', 'excadrill', 'exeggcute', 'exeggutor', 'exploud', 'falinks', 'farfetchd', 'farigiraf', 'fearow', 'feebas', 'fennekin', 'feraligatr', 'ferroseed', 'ferrothorn', 'fidough', 'finizen', 'finneon', 'flaaffy', 'flabebe', 'flamigo', 'flapple', 'flareon', 'fletchinder', 'fletchling', 'flittle', 'floatzel', 'floette', 'floragato', 'florges', 'flutter-mane', 'flygon', 'fomantis', 'foongus', 'forretress', 'fraxure', 'frigibax', 'frillish', 'froakie', 'frogadier', 'froslass', 'frosmoth', 'fuecoco', 'furfrou', 'furret', 'gabite', 'gallade', 'galvantula', 'garbodor', 'garchomp', 'gardevoir', 'garganacl', 'gastly', 'gastrodon', 'genesect', 'gengar', 'geodude', 'gholdengo', 'gible', 'gigalith', 'gimmighoul', 'girafarig', 'giratina-altered', 'glaceon', 'glalie', 'glameow', 'glastrier', 'gligar', 'glimmet', 'glimmora', 'gliscor', 'gloom', 'gogoat', 'golbat', 'goldeen', 'golduck', 'golem', 'golett', 'golisopod', 'golurk', 'goodra', 'goomy', 'gorebyss', 'gossifleur', 'gothita', 'gothitelle', 'gothorita', 'gourgeist-average', 'grafaiai', 'granbull', 'grapploct', 'graveler', 'great-tusk', 'greavard', 'greedent', 'greninja', 'grimer', 'grimmsnarl', 'grookey', 'grotle', 'groudon', 'grovyle', 'growlithe', 'grubbin', 'grumpig', 'gulpin', 'gumshoos', 'gurdurr', 'guzzlord', 'gyarados', 'hakamo-o', 'happiny', 'hariyama', 'hatenna', 'hatterene', 'hattrem', 'haunter', 'hawlucha', 'haxorus', 'heatmor', 'heatran', 'heliolisk', 'helioptile', 'heracross', 'herdier', 'hippopotas', 'hippowdon', 'hitmonchan', 'hitmonlee', 'hitmontop', 'ho-oh', 'honchkrow', 'honedge', 'hoopa', 'hoothoot', 'hoppip', 'horsea', 'houndoom', 'houndour', 'houndstone', 'huntail', 'hydreigon', 'hypno', 'igglybuff', 'illumise', 'impidimp', 'incineroar', 'indeedee-male', 'infernape', 'inkay', 'inteleon', 'iron-bundle', 'iron-hands', 'iron-jugulis', 'iron-moth', 'iron-thorns', 'iron-treads', 'ivysaur', 'jangmo-o', 'jellicent', 'jigglypuff', 'jirachi', 'jolteon', 'joltik', 'jumpluff', 'jynx', 'kabuto', 'kabutops', 'kadabra', 'kakuna', 'kangaskhan', 'karrablast', 'kartana', 'kecleon', 'keldeo-ordinary', 'kilowattrel', 'kingambit', 'kingdra', 'kingler', 'kirlia', 'klang', 'klawf', 'kleavor', 'klefki', 'klink', 'klinklang', 'koffing', 'komala', 'kommo-o', 'krabby', 'kricketot', 'kricketune', 'krokorok', 'krookodile', 'kubfu', 'kyogre', 'kyurem', 'lairon', 'lampent', 'landorus-incarnate', 'lanturn', 'lapras', 'larvesta', 'larvitar', 'latias', 'latios', 'leafeon', 'leavanny', 'lechonk', 'ledian', 'ledyba', 'lickilicky', 'lickitung', 'liepard', 'lileep', 'lilligant', 'lillipup', 'linoone', 'litleo', 'litten', 'litwick', 'lokix', 'lombre', 'lopunny', 'lotad', 'loudred', 'lucario', 'ludicolo', 'lugia', 'lumineon', 'lunala', 'lunatone', 'lurantis', 'luvdisc', 'luxio', 'luxray', 'lycanroc-midday', 'mabosstiff', 'machamp', 'machoke', 'machop', 'magby', 'magcargo', 'magearna', 'magikarp', 'magmar', 'magmortar', 'magnemite', 'magneton', 'magnezone', 'makuhita', 'malamar', 'mamoswine', 'manaphy', 'mandibuzz', 'manectric', 'mankey', 'mantine', 'mantyke', 'maractus', 'mareanie', 'mareep', 'marill', 'marowak', 'marshadow', 'marshtomp', 'maschiff', 'masquerain', 'maushold-family-of-four', 'mawile', 'medicham', 'meditite', 'meganium', 'melmetal', 'meloetta-aria', 'meltan', 'meowscarada', 'meowstic-male', 'meowth', 'mesprit', 'metagross', 'metang', 'metapod', 'mew', 'mewtwo', 'mienfoo', 'mienshao', 'mightyena', 'milcery', 'milotic', 'miltank', 'mime-jr', 'mimikyu-disguised', 'minccino', 'minior-red-meteor', 'minun', 'misdreavus', 'mismagius', 'moltres', 'monferno', 'morelull', 'morgrem', 'morpeko-full-belly', 'mothim', 'mr-mime', 'mr-rime', 'mudbray', 'mudkip', 'mudsdale', 'muk', 'munchlax', 'munna', 'murkrow', 'musharna', 'nacli', 'naclstack', 'naganadel', 'natu', 'necrozma', 'nickit', 'nidoking', 'nidoqueen', 'nidoran-f', 'nidoran-m', 'nidorina', 'nidorino', 'nihilego', 'nincada', 'ninetales', 'ninjask', 'noctowl', 'noibat', 'noivern', 'nosepass', 'numel', 'nuzleaf', 'nymble', 'obstagoon', 'octillery', 'oddish', 'oinkologne-male', 'omanyte', 'omastar', 'onix', 'oranguru', 'orbeetle', 'oricorio-baile', 'orthworm', 'oshawott', 'overqwil', 'pachirisu', 'palafin-zero', 'palkia', 'palossand', 'palpitoad', 'pancham', 'pangoro', 'panpour', 'pansage', 'pansear', 'paras', 'parasect', 'passimian', 'patrat', 'pawmi', 'pawmo', 'pawmot', 'pawniard', 'pelipper', 'perrserker', 'persian', 'petilil', 'phanpy', 'phantump', 'pheromosa', 'phione', 'pichu', 'pidgeot', 'pidgeotto', 'pidgey', 'pidove', 'pignite', 'pikachu', 'pikipek', 'piloswine', 'pincurchin', 'pineco', 'pinsir', 'piplup', 'plusle', 'poipole', 'politoed', 'poliwag', 'poliwhirl', 'poliwrath', 'polteageist', 'ponyta', 'poochyena', 'popplio', 'porygon', 'porygon-z', 'porygon2', 'primarina', 'primeape', 'prinplup', 'probopass', 'psyduck', 'pumpkaboo-average', 'pupitar', 'purrloin', 'purugly', 'pyroar', 'pyukumuku', 'quagsire', 'quaquaval', 'quaxly', 'quaxwell', 'quilava', 'quilladin', 'qwilfish', 'raboot', 'rabsca', 'raichu', 'raikou', 'ralts', 'rampardos', 'rapidash', 'raticate', 'rattata', 'rayquaza', 'regice', 'regidrago', 'regieleki', 'regigigas', 'regirock', 'registeel', 'relicanth', 'rellor', 'remoraid', 'reshiram', 'reuniclus', 'revavroom', 'rhydon', 'rhyhorn', 'rhyperior', 'ribombee', 'rillaboom', 'riolu', 'rockruff', 'roggenrola', 'rolycoly', 'rookidee', 'roselia', 'roserade', 'rotom', 'rowlet', 'rufflet', 'runerigus', 'sableye', 'salamence', 'salandit', 'salazzle', 'samurott', 'sandaconda', 'sandile', 'sandshrew', 'sandslash', 'sandy-shocks', 'sandygast', 'sawk', 'sawsbuck', 'scatterbug', 'sceptile', 'scizor', 'scolipede', 'scorbunny', 'scovillain', 'scrafty', 'scraggy', 'scream-tail', 'scyther', 'seadra', 'seaking', 'sealeo', 'seedot', 'seel', 'seismitoad', 'sentret', 'serperior', 'servine', 'seviper', 'sewaddle', 'sharpedo', 'shaymin-land', 'shedinja', 'shelgon', 'shellder', 'shellos', 'shelmet', 'shieldon', 'shiftry', 'shiinotic', 'shinx', 'shroodle', 'shroomish', 'shuckle', 'shuppet', 'sigilyph', 'silcoon', 'silicobra', 'silvally', 'simipour', 'simisage', 'simisear', 'sinistea', 'sirfetchd', 'sizzlipede', 'skarmory', 'skeledirge', 'skiddo', 'skiploom', 'skitty', 'skorupi', 'skrelp', 'skuntank', 'skwovet', 'slaking', 'slakoth', 'sliggoo', 'slither-wing', 'slowbro', 'slowking', 'slowpoke', 'slugma', 'slurpuff', 'smeargle', 'smoliv', 'smoochum', 'sneasel', 'sneasler', 'snivy', 'snom', 'snorlax', 'snorunt', 'snover', 'snubbull', 'sobble', 'solgaleo', 'solosis', 'solrock', 'spearow', 'spectrier', 'spewpa', 'spheal', 'spidops', 'spinarak', 'spinda', 'spiritomb', 'spoink', 'sprigatito', 'spritzee', 'squawkabilly-green-plumage', 'squirtle', 'stakataka', 'stantler', 'staraptor', 'staravia', 'starly', 'starmie', 'staryu', 'steelix', 'steenee', 'stonjourner', 'stoutland', 'stufful', 'stunfisk', 'stunky', 'sudowoodo', 'suicune', 'sunflora', 'sunkern', 'surskit', 'swablu', 'swadloon', 'swalot', 'swampert', 'swanna', 'swellow', 'swinub', 'swirlix', 'swoobat', 'sylveon', 'tadbulb', 'taillow', 'talonflame', 'tandemaus', 'tangela', 'tangrowth', 'tapu-bulu', 'tapu-fini', 'tapu-koko', 'tapu-lele', 'tarountula', 'tatsugiri-curly', 'tauros', 'teddiursa', 'tentacool', 'tentacruel', 'tepig', 'terrakion', 'thievul', 'throh', 'thundurus-incarnate', 'thwackey', 'timburr', 'tinkatink', 'tinkaton', 'tinkatuff', 'tirtouga', 'toedscool', 'toedscruel', 'togedemaru', 'togekiss', 'togepi', 'togetic', 'torchic', 'torkoal', 'tornadus-incarnate', 'torracat', 'torterra', 'totodile', 'toucannon', 'toxapex', 'toxel', 'toxicroak', 'toxtricity-amped', 'tranquill', 'trapinch', 'treecko', 'trevenant', 'tropius', 'trubbish', 'trumbeak', 'tsareena', 'turtonator', 'turtwig', 'tympole', 'tynamo', 'type-null', 'typhlosion', 'tyranitar', 'tyrantrum', 'tyrogue', 'tyrunt', 'umbreon', 'unfezant', 'unown', 'ursaluna', 'ursaring', 'urshifu-single-strike', 'uxie', 'vanillish', 'vanillite', 'vanilluxe', 'vaporeon', 'varoom', 'veluza', 'venipede', 'venomoth', 'venonat', 'venusaur', 'vespiquen', 'vibrava', 'victini', 'victreebel', 'vigoroth', 'vikavolt', 'vileplume', 'virizion', 'vivillon', 'volbeat', 'volcanion', 'volcarona', 'voltorb', 'vullaby', 'vulpix', 'wailmer', 'wailord', 'walrein', 'wartortle', 'watchog', 'wattrel', 'weavile', 'weedle', 'weepinbell', 'weezing', 'whimsicott', 'whirlipede', 'whiscash', 'whismur', 'wigglytuff', 'wiglett', 'wimpod', 'wingull', 'wishiwashi-solo', 'wobbuffet', 'woobat', 'wooloo', 'wooper', 'wormadam-plant', 'wugtrio', 'wurmple', 'wynaut', 'wyrdeer', 'xatu', 'xerneas', 'xurkitree', 'yamask', 'yamper', 'yanma', 'yanmega', 'yungoos', 'yveltal', 'zacian', 'zamazenta', 'zangoose', 'zapdos', 'zarude', 'zebstrika', 'zekrom', 'zeraora', 'zigzagoon', 'zoroark', 'zorua', 'zubat', 'zweilous', 'zygarde-50']\n",
      "1000\n",
      "Epoch: 0\n",
      "loss: 6.929767  [   10/20921]\n",
      "loss: 6.825555  [ 1010/20921]\n",
      "loss: 6.628315  [ 2010/20921]\n",
      "loss: 6.969485  [ 3010/20921]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 147\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch))\n\u001b[0;32m--> 147\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     test_loop(dataloader_test, model, loss)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m#epoch_loss = running_loss / len(train)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m#epoch_accuracy = 100 * correct / total\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m#print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 108\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, bs)\u001b[0m\n\u001b[1;32m    105\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    106\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m    109\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    110\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torchvision/datasets/folder.py:247\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torchvision/transforms/transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torchvision/transforms/functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/PIL/Image.py:2365\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2354\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2355\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2356\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2357\u001b[0m         )\n\u001b[1;32m   2358\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2359\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2360\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2361\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2362\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2363\u001b[0m         )\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2D_MaxPool2D = nn.Sequential(\n",
    "            nn.Conv2d(3, 30, (5, 5), stride=2),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.Conv2d(30, 60, (2, 2), stride=3),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(60, 120, (5, 5), stride=4),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9720, 1000),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.conv2D_MaxPool2D(x)\n",
    "        return logits\n",
    "\n",
    "    #Shapes de les x conforme passa per les capes\n",
    "    \"\"\" \n",
    "    class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Definir cada capa individualmente\n",
    "        self.conv1 = nn.Conv2d(3, 30, (5,5), stride=2, padding=2)\n",
    "        self.maxpool1 = nn.MaxPool2d((1,1))\n",
    "        self.conv2 = nn.Conv2d(30, 60, (2,2), stride=3)\n",
    "        self.maxpool2 = nn.MaxPool2d((1,1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(60, 120, (5,5), stride=4)\n",
    "        self.maxpool3 = nn.MaxPool2d((1,1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(12000, 1000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Paso por cada capa y imprimir las salidas entre las capas\n",
    "        print(f'Input shape: {x.shape}')\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        print(f'After conv1: {x.shape}')  # Tamaño después de la convolución 1\n",
    "\n",
    "        x = self.maxpool1(x)\n",
    "        print(f'After maxpool1: {x.shape}')  # Tamaño después del max pooling 1\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        print(f'After conv2: {x.shape}')  # Tamaño después de la convolución 2\n",
    "\n",
    "        x = self.maxpool2(x)\n",
    "        print(f'After maxpool2: {x.shape}')  # Tamaño después del max pooling 2\n",
    "\n",
    "        x = self.relu1(x)\n",
    "        print(f'After relu1: {x.shape}')  # Tamaño después de ReLU 1\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        print(f'After conv3: {x.shape}')  # Tamaño después de la convolución 3\n",
    "\n",
    "        x = self.maxpool3(x)\n",
    "        print(f'After maxpool3: {x.shape}')  # Tamaño después de max pooling 3\n",
    "\n",
    "        x = self.relu2(x)\n",
    "        print(f'After relu2: {x.shape}')  # Tamaño después de ReLU 2\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        print(f'After flatten: {x.shape}')  # Tamaño después de aplanar la imagen\n",
    "\n",
    "        x = self.fc(x)\n",
    "        print(f'After fc (linear): {x.shape}')  # Tamaño después de la capa lineal\n",
    "\n",
    "        return x\n",
    "    \"\"\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((244, 244)), # Redimensionar a 200x200p\n",
    "    transforms.ToTensor(), # Convertir imatges a tensors de PyTorch\n",
    "])\n",
    "\n",
    "data_path = '/home/itibcn/Desktop/Torch/datasets/pokemondataset/train'\n",
    "data_path2 = '/home/itibcn/Desktop/Torch/datasets/pokemondataset/test'\n",
    "\n",
    "train = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "test = datasets.ImageFolder(root=data_path2, transform = transform)\n",
    "\n",
    "dataloader_train = DataLoader(train, batch_size=10, shuffle=True)\n",
    "dataloader_test = DataLoader(test, batch_size=10, shuffle=True)\n",
    "\n",
    "output_dimension = len(datasets.ImageFolder(root=data_path).classes)\n",
    "bs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 100\n",
    "\n",
    "#Inicialitzar el model, funcio de perdua i optimitzador\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Mostrar las clases\n",
    "print(f\"Clases del dataset: {train.classes}\")\n",
    "print(len(train.classes))\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, bs):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * bs + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)    \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    train_loop(dataloader_train, model, loss, optimizer, bs)\n",
    "    test_loop(dataloader_test, model, loss)\n",
    "\n",
    "    #epoch_loss = running_loss / len(train)\n",
    "    #epoch_accuracy = 100 * correct / total\n",
    "    #print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "    \n",
    "print('Entrenament finalitzat.')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model_path = '/home/itibcn/Desktop/Torch/modelPokimon.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4667/1957200561.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado exitosamente.\n",
      "El Pokémon predicho es: lucario\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define nuevamente la clase NeuralNetwork\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2D_MaxPool2D = nn.Sequential(\n",
    "            nn.Conv2d(3, 30, (5, 5), stride=2),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.Conv2d(30, 60, (2, 2), stride=3),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(60, 120, (5, 5), stride=4),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9720, 1000),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2D_MaxPool2D(x)\n",
    "        return x\n",
    "\n",
    "# Función para cargar y predecir\n",
    "def predict_pokemon(image_path, model, classes, device):\n",
    "    \"\"\"\n",
    "    Predice el Pokémon en una imagen dada utilizando el modelo entrenado.\n",
    "\n",
    "    :param image_path: Ruta a la imagen del Pokémon\n",
    "    :param model: Modelo preentrenado para clasificar Pokémon\n",
    "    :param classes: Lista de nombres de clases (Pokémon)\n",
    "    :param device: CPU o GPU donde se ejecutará la predicción\n",
    "    :return: Nombre del Pokémon predicho\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((244, 244)),  # Tamaño de entrada según el entrenamiento\n",
    "        transforms.ToTensor(),         \n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalización\n",
    "    ])\n",
    "\n",
    "    # Procesa la imagen\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')  # Convertir a RGB\n",
    "        image = transform(image).unsqueeze(0)         # Añadir la dimensión batch\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar la imagen: {e}\")\n",
    "        return None\n",
    "\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Realiza la predicción\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_class = classes[predicted.item()]\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Ruta al modelo guardado\n",
    "model_path = \"modelPokimon.pth\" #Pesos del model entrenat guardats en aquesta variable\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Clases definidas en el entrenamiento\n",
    "classes = ['abomasnow', 'abra', 'absol', 'accelgor', 'aegislash-shield', 'aerodactyl', 'aggron', 'aipom', 'alakazam', 'alcremie', 'alomomola', 'altaria', 'amaura', 'ambipom', 'amoonguss', 'ampharos', 'annihilape', 'anorith', 'appletun', 'applin', 'araquanid', 'arbok', 'arboliva', 'arcanine', 'arceus', 'archen', 'archeops', 'arctibax', 'arctovish', 'arctozolt', 'ariados', 'armaldo', 'armarouge', 'aromatisse', 'aron', 'arrokuda', 'articuno', 'audino', 'aurorus', 'avalugg', 'axew', 'azelf', 'azumarill', 'azurill', 'bagon', 'baltoy', 'banette', 'barbaracle', 'barboach', 'barraskewda', 'basculegion-male', 'basculin-red-striped', 'bastiodon', 'baxcalibur', 'bayleef', 'beartic', 'beautifly', 'beedrill', 'beheeyem', 'beldum', 'bellibolt', 'bellossom', 'bellsprout', 'bergmite', 'bewear', 'bibarel', 'bidoof', 'binacle', 'bisharp', 'blacephalon', 'blastoise', 'blaziken', 'blipbug', 'blissey', 'blitzle', 'boldore', 'boltund', 'bombirdier', 'bonsly', 'bouffalant', 'bounsweet', 'braixen', 'brambleghast', 'bramblin', 'braviary', 'breloom', 'brionne', 'bronzong', 'bronzor', 'brute-bonnet', 'bruxish', 'budew', 'buizel', 'bulbasaur', 'buneary', 'bunnelby', 'burmy', 'butterfree', 'buzzwole', 'cacnea', 'cacturne', 'calyrex', 'camerupt', 'capsakid', 'carbink', 'carkol', 'carnivine', 'carracosta', 'carvanha', 'cascoon', 'castform', 'caterpie', 'celebi', 'celesteela', 'centiskorch', 'ceruledge', 'cetitan', 'cetoddle', 'chandelure', 'chansey', 'charcadet', 'charizard', 'charjabug', 'charmander', 'charmeleon', 'chatot', 'cherrim', 'cherubi', 'chesnaught', 'chespin', 'chewtle', 'chikorita', 'chimchar', 'chimecho', 'chinchou', 'chingling', 'cinccino', 'cinderace', 'clamperl', 'clauncher', 'clawitzer', 'claydol', 'clefable', 'clefairy', 'cleffa', 'clobbopus', 'clodsire', 'cloyster', 'coalossal', 'cobalion', 'cofagrigus', 'combee', 'combusken', 'comfey', 'conkeldurr', 'copperajah', 'corphish', 'corsola', 'corviknight', 'corvisquire', 'cosmoem', 'cosmog', 'cottonee', 'crabominable', 'crabrawler', 'cradily', 'cramorant', 'cranidos', 'crawdaunt', 'cresselia', 'croagunk', 'crobat', 'crocalor', 'croconaw', 'crustle', 'cryogonal', 'cubchoo', 'cubone', 'cufant', 'cursola', 'cutiefly', 'cyclizar', 'cyndaquil', 'dachsbun', 'darkrai', 'darmanitan-standard', 'dartrix', 'darumaka', 'decidueye', 'dedenne', 'deerling', 'deino', 'delcatty', 'delibird', 'delphox', 'deoxys-normal', 'dewgong', 'dewott', 'dewpider', 'dhelmise', 'dialga', 'diancie', 'diggersby', 'diglett', 'ditto', 'dodrio', 'doduo', 'dolliv', 'dondozo', 'donphan', 'dottler', 'doublade', 'dracovish', 'dracozolt', 'dragalge', 'dragapult', 'dragonair', 'dragonite', 'drakloak', 'drampa', 'drapion', 'dratini', 'drednaw', 'dreepy', 'drifblim', 'drifloon', 'drilbur', 'drizzile', 'drowzee', 'druddigon', 'dubwool', 'ducklett', 'dudunsparce-two-segment', 'dugtrio', 'dunsparce', 'duosion', 'duraludon', 'durant', 'dusclops', 'dusknoir', 'duskull', 'dustox', 'dwebble', 'eelektrik', 'eelektross', 'eevee', 'eiscue-ice', 'ekans', 'eldegoss', 'electabuzz', 'electivire', 'electrike', 'electrode', 'elekid', 'elgyem', 'emboar', 'emolga', 'empoleon', 'enamorus-incarnate', 'entei', 'escavalier', 'espathra', 'espeon', 'espurr', 'eternatus', 'excadrill', 'exeggcute', 'exeggutor', 'exploud', 'falinks', 'farfetchd', 'farigiraf', 'fearow', 'feebas', 'fennekin', 'feraligatr', 'ferroseed', 'ferrothorn', 'fidough', 'finizen', 'finneon', 'flaaffy', 'flabebe', 'flamigo', 'flapple', 'flareon', 'fletchinder', 'fletchling', 'flittle', 'floatzel', 'floette', 'floragato', 'florges', 'flutter-mane', 'flygon', 'fomantis', 'foongus', 'forretress', 'fraxure', 'frigibax', 'frillish', 'froakie', 'frogadier', 'froslass', 'frosmoth', 'fuecoco', 'furfrou', 'furret', 'gabite', 'gallade', 'galvantula', 'garbodor', 'garchomp', 'gardevoir', 'garganacl', 'gastly', 'gastrodon', 'genesect', 'gengar', 'geodude', 'gholdengo', 'gible', 'gigalith', 'gimmighoul', 'girafarig', 'giratina-altered', 'glaceon', 'glalie', 'glameow', 'glastrier', 'gligar', 'glimmet', 'glimmora', 'gliscor', 'gloom', 'gogoat', 'golbat', 'goldeen', 'golduck', 'golem', 'golett', 'golisopod', 'golurk', 'goodra', 'goomy', 'gorebyss', 'gossifleur', 'gothita', 'gothitelle', 'gothorita', 'gourgeist-average', 'grafaiai', 'granbull', 'grapploct', 'graveler', 'great-tusk', 'greavard', 'greedent', 'greninja', 'grimer', 'grimmsnarl', 'grookey', 'grotle', 'groudon', 'grovyle', 'growlithe', 'grubbin', 'grumpig', 'gulpin', 'gumshoos', 'gurdurr', 'guzzlord', 'gyarados', 'hakamo-o', 'happiny', 'hariyama', 'hatenna', 'hatterene', 'hattrem', 'haunter', 'hawlucha', 'haxorus', 'heatmor', 'heatran', 'heliolisk', 'helioptile', 'heracross', 'herdier', 'hippopotas', 'hippowdon', 'hitmonchan', 'hitmonlee', 'hitmontop', 'ho-oh', 'honchkrow', 'honedge', 'hoopa', 'hoothoot', 'hoppip', 'horsea', 'houndoom', 'houndour', 'houndstone', 'huntail', 'hydreigon', 'hypno', 'igglybuff', 'illumise', 'impidimp', 'incineroar', 'indeedee-male', 'infernape', 'inkay', 'inteleon', 'iron-bundle', 'iron-hands', 'iron-jugulis', 'iron-moth', 'iron-thorns', 'iron-treads', 'ivysaur', 'jangmo-o', 'jellicent', 'jigglypuff', 'jirachi', 'jolteon', 'joltik', 'jumpluff', 'jynx', 'kabuto', 'kabutops', 'kadabra', 'kakuna', 'kangaskhan', 'karrablast', 'kartana', 'kecleon', 'keldeo-ordinary', 'kilowattrel', 'kingambit', 'kingdra', 'kingler', 'kirlia', 'klang', 'klawf', 'kleavor', 'klefki', 'klink', 'klinklang', 'koffing', 'komala', 'kommo-o', 'krabby', 'kricketot', 'kricketune', 'krokorok', 'krookodile', 'kubfu', 'kyogre', 'kyurem', 'lairon', 'lampent', 'landorus-incarnate', 'lanturn', 'lapras', 'larvesta', 'larvitar', 'latias', 'latios', 'leafeon', 'leavanny', 'lechonk', 'ledian', 'ledyba', 'lickilicky', 'lickitung', 'liepard', 'lileep', 'lilligant', 'lillipup', 'linoone', 'litleo', 'litten', 'litwick', 'lokix', 'lombre', 'lopunny', 'lotad', 'loudred', 'lucario', 'ludicolo', 'lugia', 'lumineon', 'lunala', 'lunatone', 'lurantis', 'luvdisc', 'luxio', 'luxray', 'lycanroc-midday', 'mabosstiff', 'machamp', 'machoke', 'machop', 'magby', 'magcargo', 'magearna', 'magikarp', 'magmar', 'magmortar', 'magnemite', 'magneton', 'magnezone', 'makuhita', 'malamar', 'mamoswine', 'manaphy', 'mandibuzz', 'manectric', 'mankey', 'mantine', 'mantyke', 'maractus', 'mareanie', 'mareep', 'marill', 'marowak', 'marshadow', 'marshtomp', 'maschiff', 'masquerain', 'maushold-family-of-four', 'mawile', 'medicham', 'meditite', 'meganium', 'melmetal', 'meloetta-aria', 'meltan', 'meowscarada', 'meowstic-male', 'meowth', 'mesprit', 'metagross', 'metang', 'metapod', 'mew', 'mewtwo', 'mienfoo', 'mienshao', 'mightyena', 'milcery', 'milotic', 'miltank', 'mime-jr', 'mimikyu-disguised', 'minccino', 'minior-red-meteor', 'minun', 'misdreavus', 'mismagius', 'moltres', 'monferno', 'morelull', 'morgrem', 'morpeko-full-belly', 'mothim', 'mr-mime', 'mr-rime', 'mudbray', 'mudkip', 'mudsdale', 'muk', 'munchlax', 'munna', 'murkrow', 'musharna', 'nacli', 'naclstack', 'naganadel', 'natu', 'necrozma', 'nickit', 'nidoking', 'nidoqueen', 'nidoran-f', 'nidoran-m', 'nidorina', 'nidorino', 'nihilego', 'nincada', 'ninetales', 'ninjask', 'noctowl', 'noibat', 'noivern', 'nosepass', 'numel', 'nuzleaf', 'nymble', 'obstagoon', 'octillery', 'oddish', 'oinkologne-male', 'omanyte', 'omastar', 'onix', 'oranguru', 'orbeetle', 'oricorio-baile', 'orthworm', 'oshawott', 'overqwil', 'pachirisu', 'palafin-zero', 'palkia', 'palossand', 'palpitoad', 'pancham', 'pangoro', 'panpour', 'pansage', 'pansear', 'paras', 'parasect', 'passimian', 'patrat', 'pawmi', 'pawmo', 'pawmot', 'pawniard', 'pelipper', 'perrserker', 'persian', 'petilil', 'phanpy', 'phantump', 'pheromosa', 'phione', 'pichu', 'pidgeot', 'pidgeotto', 'pidgey', 'pidove', 'pignite', 'pikachu', 'pikipek', 'piloswine', 'pincurchin', 'pineco', 'pinsir', 'piplup', 'plusle', 'poipole', 'politoed', 'poliwag', 'poliwhirl', 'poliwrath', 'polteageist', 'ponyta', 'poochyena', 'popplio', 'porygon', 'porygon-z', 'porygon2', 'primarina', 'primeape', 'prinplup', 'probopass', 'psyduck', 'pumpkaboo-average', 'pupitar', 'purrloin', 'purugly', 'pyroar', 'pyukumuku', 'quagsire', 'quaquaval', 'quaxly', 'quaxwell', 'quilava', 'quilladin', 'qwilfish', 'raboot', 'rabsca', 'raichu', 'raikou', 'ralts', 'rampardos', 'rapidash', 'raticate', 'rattata', 'rayquaza', 'regice', 'regidrago', 'regieleki', 'regigigas', 'regirock', 'registeel', 'relicanth', 'rellor', 'remoraid', 'reshiram', 'reuniclus', 'revavroom', 'rhydon', 'rhyhorn', 'rhyperior', 'ribombee', 'rillaboom', 'riolu', 'rockruff', 'roggenrola', 'rolycoly', 'rookidee', 'roselia', 'roserade', 'rotom', 'rowlet', 'rufflet', 'runerigus', 'sableye', 'salamence', 'salandit', 'salazzle', 'samurott', 'sandaconda', 'sandile', 'sandshrew', 'sandslash', 'sandy-shocks', 'sandygast', 'sawk', 'sawsbuck', 'scatterbug', 'sceptile', 'scizor', 'scolipede', 'scorbunny', 'scovillain', 'scrafty', 'scraggy', 'scream-tail', 'scyther', 'seadra', 'seaking', 'sealeo', 'seedot', 'seel', 'seismitoad', 'sentret', 'serperior', 'servine', 'seviper', 'sewaddle', 'sharpedo', 'shaymin-land', 'shedinja', 'shelgon', 'shellder', 'shellos', 'shelmet', 'shieldon', 'shiftry', 'shiinotic', 'shinx', 'shroodle', 'shroomish', 'shuckle', 'shuppet', 'sigilyph', 'silcoon', 'silicobra', 'silvally', 'simipour', 'simisage', 'simisear', 'sinistea', 'sirfetchd', 'sizzlipede', 'skarmory', 'skeledirge', 'skiddo', 'skiploom', 'skitty', 'skorupi', 'skrelp', 'skuntank', 'skwovet', 'slaking', 'slakoth', 'sliggoo', 'slither-wing', 'slowbro', 'slowking', 'slowpoke', 'slugma', 'slurpuff', 'smeargle', 'smoliv', 'smoochum', 'sneasel', 'sneasler', 'snivy', 'snom', 'snorlax', 'snorunt', 'snover', 'snubbull', 'sobble', 'solgaleo', 'solosis', 'solrock', 'spearow', 'spectrier', 'spewpa', 'spheal', 'spidops', 'spinarak', 'spinda', 'spiritomb', 'spoink', 'sprigatito', 'spritzee', 'squawkabilly-green-plumage', 'squirtle', 'stakataka', 'stantler', 'staraptor', 'staravia', 'starly', 'starmie', 'staryu', 'steelix', 'steenee', 'stonjourner', 'stoutland', 'stufful', 'stunfisk', 'stunky', 'sudowoodo', 'suicune', 'sunflora', 'sunkern', 'surskit', 'swablu', 'swadloon', 'swalot', 'swampert', 'swanna', 'swellow', 'swinub', 'swirlix', 'swoobat', 'sylveon', 'tadbulb', 'taillow', 'talonflame', 'tandemaus', 'tangela', 'tangrowth', 'tapu-bulu', 'tapu-fini', 'tapu-koko', 'tapu-lele', 'tarountula', 'tatsugiri-curly', 'tauros', 'teddiursa', 'tentacool', 'tentacruel', 'tepig', 'terrakion', 'thievul', 'throh', 'thundurus-incarnate', 'thwackey', 'timburr', 'tinkatink', 'tinkaton', 'tinkatuff', 'tirtouga', 'toedscool', 'toedscruel', 'togedemaru', 'togekiss', 'togepi', 'togetic', 'torchic', 'torkoal', 'tornadus-incarnate', 'torracat', 'torterra', 'totodile', 'toucannon', 'toxapex', 'toxel', 'toxicroak', 'toxtricity-amped', 'tranquill', 'trapinch', 'treecko', 'trevenant', 'tropius', 'trubbish', 'trumbeak', 'tsareena', 'turtonator', 'turtwig', 'tympole', 'tynamo', 'type-null', 'typhlosion', 'tyranitar', 'tyrantrum', 'tyrogue', 'tyrunt', 'umbreon', 'unfezant', 'unown', 'ursaluna', 'ursaring', 'urshifu-single-strike', 'uxie', 'vanillish', 'vanillite', 'vanilluxe', 'vaporeon', 'varoom', 'veluza', 'venipede', 'venomoth', 'venonat', 'venusaur', 'vespiquen', 'vibrava', 'victini', 'victreebel', 'vigoroth', 'vikavolt', 'vileplume', 'virizion', 'vivillon', 'volbeat', 'volcanion', 'volcarona', 'voltorb', 'vullaby', 'vulpix', 'wailmer', 'wailord', 'walrein', 'wartortle', 'watchog', 'wattrel', 'weavile', 'weedle', 'weepinbell', 'weezing', 'whimsicott', 'whirlipede', 'whiscash', 'whismur', 'wigglytuff', 'wiglett', 'wimpod', 'wingull', 'wishiwashi-solo', 'wobbuffet', 'woobat', 'wooloo', 'wooper', 'wormadam-plant', 'wugtrio', 'wurmple', 'wynaut', 'wyrdeer', 'xatu', 'xerneas', 'xurkitree', 'yamask', 'yamper', 'yanma', 'yanmega', 'yungoos', 'yveltal', 'zacian', 'zamazenta', 'zangoose', 'zapdos', 'zarude', 'zebstrika', 'zekrom', 'zeraora', 'zigzagoon', 'zoroark', 'zorua', 'zubat', 'zweilous', 'zygarde-50']\n",
    "\n",
    "\n",
    "# Carga del modelo\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print(\"Modelo cargado exitosamente.\")\n",
    "\n",
    "# Ruta de la imagen\n",
    "image_path = \"/home/itibcn/Desktop/Torch/ModelsEntrenats/AdivinaPokemon/jigglypuff.jpg\"\n",
    "\n",
    "# Predicción\n",
    "predicted_pokemon = predict_pokemon(image_path, model, classes, device)\n",
    "print(f\"El Pokémon predicho es: {predicted_pokemon}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases del dataset: ['abomasnow', 'abra', 'absol', 'accelgor', 'aegislash-shield', 'aerodactyl', 'aggron', 'aipom', 'alakazam', 'alcremie', 'alomomola', 'altaria', 'amaura', 'ambipom', 'amoonguss', 'ampharos', 'annihilape', 'anorith', 'appletun', 'applin', 'araquanid', 'arbok', 'arboliva', 'arcanine', 'arceus', 'archen', 'archeops', 'arctibax', 'arctovish', 'arctozolt', 'ariados', 'armaldo', 'armarouge', 'aromatisse', 'aron', 'arrokuda', 'articuno', 'audino', 'aurorus', 'avalugg', 'axew', 'azelf', 'azumarill', 'azurill', 'bagon', 'baltoy', 'banette', 'barbaracle', 'barboach', 'barraskewda', 'basculegion-male', 'basculin-red-striped', 'bastiodon', 'baxcalibur', 'bayleef', 'beartic', 'beautifly', 'beedrill', 'beheeyem', 'beldum', 'bellibolt', 'bellossom', 'bellsprout', 'bergmite', 'bewear', 'bibarel', 'bidoof', 'binacle', 'bisharp', 'blacephalon', 'blastoise', 'blaziken', 'blipbug', 'blissey', 'blitzle', 'boldore', 'boltund', 'bombirdier', 'bonsly', 'bouffalant', 'bounsweet', 'braixen', 'brambleghast', 'bramblin', 'braviary', 'breloom', 'brionne', 'bronzong', 'bronzor', 'brute-bonnet', 'bruxish', 'budew', 'buizel', 'bulbasaur', 'buneary', 'bunnelby', 'burmy', 'butterfree', 'buzzwole', 'cacnea', 'cacturne', 'calyrex', 'camerupt', 'capsakid', 'carbink', 'carkol', 'carnivine', 'carracosta', 'carvanha', 'cascoon', 'castform', 'caterpie', 'celebi', 'celesteela', 'centiskorch', 'ceruledge', 'cetitan', 'cetoddle', 'chandelure', 'chansey', 'charcadet', 'charizard', 'charjabug', 'charmander', 'charmeleon', 'chatot', 'cherrim', 'cherubi', 'chesnaught', 'chespin', 'chewtle', 'chikorita', 'chimchar', 'chimecho', 'chinchou', 'chingling', 'cinccino', 'cinderace', 'clamperl', 'clauncher', 'clawitzer', 'claydol', 'clefable', 'clefairy', 'cleffa', 'clobbopus', 'clodsire', 'cloyster', 'coalossal', 'cobalion', 'cofagrigus', 'combee', 'combusken', 'comfey', 'conkeldurr', 'copperajah', 'corphish', 'corsola', 'corviknight', 'corvisquire', 'cosmoem', 'cosmog', 'cottonee', 'crabominable', 'crabrawler', 'cradily', 'cramorant', 'cranidos', 'crawdaunt', 'cresselia', 'croagunk', 'crobat', 'crocalor', 'croconaw', 'crustle', 'cryogonal', 'cubchoo', 'cubone', 'cufant', 'cursola', 'cutiefly', 'cyclizar', 'cyndaquil', 'dachsbun', 'darkrai', 'darmanitan-standard', 'dartrix', 'darumaka', 'decidueye', 'dedenne', 'deerling', 'deino', 'delcatty', 'delibird', 'delphox', 'deoxys-normal', 'dewgong', 'dewott', 'dewpider', 'dhelmise', 'dialga', 'diancie', 'diggersby', 'diglett', 'ditto', 'dodrio', 'doduo', 'dolliv', 'dondozo', 'donphan', 'dottler', 'doublade', 'dracovish', 'dracozolt', 'dragalge', 'dragapult', 'dragonair', 'dragonite', 'drakloak', 'drampa', 'drapion', 'dratini', 'drednaw', 'dreepy', 'drifblim', 'drifloon', 'drilbur', 'drizzile', 'drowzee', 'druddigon', 'dubwool', 'ducklett', 'dudunsparce-two-segment', 'dugtrio', 'dunsparce', 'duosion', 'duraludon', 'durant', 'dusclops', 'dusknoir', 'duskull', 'dustox', 'dwebble', 'eelektrik', 'eelektross', 'eevee', 'eiscue-ice', 'ekans', 'eldegoss', 'electabuzz', 'electivire', 'electrike', 'electrode', 'elekid', 'elgyem', 'emboar', 'emolga', 'empoleon', 'enamorus-incarnate', 'entei', 'escavalier', 'espathra', 'espeon', 'espurr', 'eternatus', 'excadrill', 'exeggcute', 'exeggutor', 'exploud', 'falinks', 'farfetchd', 'farigiraf', 'fearow', 'feebas', 'fennekin', 'feraligatr', 'ferroseed', 'ferrothorn', 'fidough', 'finizen', 'finneon', 'flaaffy', 'flabebe', 'flamigo', 'flapple', 'flareon', 'fletchinder', 'fletchling', 'flittle', 'floatzel', 'floette', 'floragato', 'florges', 'flutter-mane', 'flygon', 'fomantis', 'foongus', 'forretress', 'fraxure', 'frigibax', 'frillish', 'froakie', 'frogadier', 'froslass', 'frosmoth', 'fuecoco', 'furfrou', 'furret', 'gabite', 'gallade', 'galvantula', 'garbodor', 'garchomp', 'gardevoir', 'garganacl', 'gastly', 'gastrodon', 'genesect', 'gengar', 'geodude', 'gholdengo', 'gible', 'gigalith', 'gimmighoul', 'girafarig', 'giratina-altered', 'glaceon', 'glalie', 'glameow', 'glastrier', 'gligar', 'glimmet', 'glimmora', 'gliscor', 'gloom', 'gogoat', 'golbat', 'goldeen', 'golduck', 'golem', 'golett', 'golisopod', 'golurk', 'goodra', 'goomy', 'gorebyss', 'gossifleur', 'gothita', 'gothitelle', 'gothorita', 'gourgeist-average', 'grafaiai', 'granbull', 'grapploct', 'graveler', 'great-tusk', 'greavard', 'greedent', 'greninja', 'grimer', 'grimmsnarl', 'grookey', 'grotle', 'groudon', 'grovyle', 'growlithe', 'grubbin', 'grumpig', 'gulpin', 'gumshoos', 'gurdurr', 'guzzlord', 'gyarados', 'hakamo-o', 'happiny', 'hariyama', 'hatenna', 'hatterene', 'hattrem', 'haunter', 'hawlucha', 'haxorus', 'heatmor', 'heatran', 'heliolisk', 'helioptile', 'heracross', 'herdier', 'hippopotas', 'hippowdon', 'hitmonchan', 'hitmonlee', 'hitmontop', 'ho-oh', 'honchkrow', 'honedge', 'hoopa', 'hoothoot', 'hoppip', 'horsea', 'houndoom', 'houndour', 'houndstone', 'huntail', 'hydreigon', 'hypno', 'igglybuff', 'illumise', 'impidimp', 'incineroar', 'indeedee-male', 'infernape', 'inkay', 'inteleon', 'iron-bundle', 'iron-hands', 'iron-jugulis', 'iron-moth', 'iron-thorns', 'iron-treads', 'ivysaur', 'jangmo-o', 'jellicent', 'jigglypuff', 'jirachi', 'jolteon', 'joltik', 'jumpluff', 'jynx', 'kabuto', 'kabutops', 'kadabra', 'kakuna', 'kangaskhan', 'karrablast', 'kartana', 'kecleon', 'keldeo-ordinary', 'kilowattrel', 'kingambit', 'kingdra', 'kingler', 'kirlia', 'klang', 'klawf', 'kleavor', 'klefki', 'klink', 'klinklang', 'koffing', 'komala', 'kommo-o', 'krabby', 'kricketot', 'kricketune', 'krokorok', 'krookodile', 'kubfu', 'kyogre', 'kyurem', 'lairon', 'lampent', 'landorus-incarnate', 'lanturn', 'lapras', 'larvesta', 'larvitar', 'latias', 'latios', 'leafeon', 'leavanny', 'lechonk', 'ledian', 'ledyba', 'lickilicky', 'lickitung', 'liepard', 'lileep', 'lilligant', 'lillipup', 'linoone', 'litleo', 'litten', 'litwick', 'lokix', 'lombre', 'lopunny', 'lotad', 'loudred', 'lucario', 'ludicolo', 'lugia', 'lumineon', 'lunala', 'lunatone', 'lurantis', 'luvdisc', 'luxio', 'luxray', 'lycanroc-midday', 'mabosstiff', 'machamp', 'machoke', 'machop', 'magby', 'magcargo', 'magearna', 'magikarp', 'magmar', 'magmortar', 'magnemite', 'magneton', 'magnezone', 'makuhita', 'malamar', 'mamoswine', 'manaphy', 'mandibuzz', 'manectric', 'mankey', 'mantine', 'mantyke', 'maractus', 'mareanie', 'mareep', 'marill', 'marowak', 'marshadow', 'marshtomp', 'maschiff', 'masquerain', 'maushold-family-of-four', 'mawile', 'medicham', 'meditite', 'meganium', 'melmetal', 'meloetta-aria', 'meltan', 'meowscarada', 'meowstic-male', 'meowth', 'mesprit', 'metagross', 'metang', 'metapod', 'mew', 'mewtwo', 'mienfoo', 'mienshao', 'mightyena', 'milcery', 'milotic', 'miltank', 'mime-jr', 'mimikyu-disguised', 'minccino', 'minior-red-meteor', 'minun', 'misdreavus', 'mismagius', 'moltres', 'monferno', 'morelull', 'morgrem', 'morpeko-full-belly', 'mothim', 'mr-mime', 'mr-rime', 'mudbray', 'mudkip', 'mudsdale', 'muk', 'munchlax', 'munna', 'murkrow', 'musharna', 'nacli', 'naclstack', 'naganadel', 'natu', 'necrozma', 'nickit', 'nidoking', 'nidoqueen', 'nidoran-f', 'nidoran-m', 'nidorina', 'nidorino', 'nihilego', 'nincada', 'ninetales', 'ninjask', 'noctowl', 'noibat', 'noivern', 'nosepass', 'numel', 'nuzleaf', 'nymble', 'obstagoon', 'octillery', 'oddish', 'oinkologne-male', 'omanyte', 'omastar', 'onix', 'oranguru', 'orbeetle', 'oricorio-baile', 'orthworm', 'oshawott', 'overqwil', 'pachirisu', 'palafin-zero', 'palkia', 'palossand', 'palpitoad', 'pancham', 'pangoro', 'panpour', 'pansage', 'pansear', 'paras', 'parasect', 'passimian', 'patrat', 'pawmi', 'pawmo', 'pawmot', 'pawniard', 'pelipper', 'perrserker', 'persian', 'petilil', 'phanpy', 'phantump', 'pheromosa', 'phione', 'pichu', 'pidgeot', 'pidgeotto', 'pidgey', 'pidove', 'pignite', 'pikachu', 'pikipek', 'piloswine', 'pincurchin', 'pineco', 'pinsir', 'piplup', 'plusle', 'poipole', 'politoed', 'poliwag', 'poliwhirl', 'poliwrath', 'polteageist', 'ponyta', 'poochyena', 'popplio', 'porygon', 'porygon-z', 'porygon2', 'primarina', 'primeape', 'prinplup', 'probopass', 'psyduck', 'pumpkaboo-average', 'pupitar', 'purrloin', 'purugly', 'pyroar', 'pyukumuku', 'quagsire', 'quaquaval', 'quaxly', 'quaxwell', 'quilava', 'quilladin', 'qwilfish', 'raboot', 'rabsca', 'raichu', 'raikou', 'ralts', 'rampardos', 'rapidash', 'raticate', 'rattata', 'rayquaza', 'regice', 'regidrago', 'regieleki', 'regigigas', 'regirock', 'registeel', 'relicanth', 'rellor', 'remoraid', 'reshiram', 'reuniclus', 'revavroom', 'rhydon', 'rhyhorn', 'rhyperior', 'ribombee', 'rillaboom', 'riolu', 'rockruff', 'roggenrola', 'rolycoly', 'rookidee', 'roselia', 'roserade', 'rotom', 'rowlet', 'rufflet', 'runerigus', 'sableye', 'salamence', 'salandit', 'salazzle', 'samurott', 'sandaconda', 'sandile', 'sandshrew', 'sandslash', 'sandy-shocks', 'sandygast', 'sawk', 'sawsbuck', 'scatterbug', 'sceptile', 'scizor', 'scolipede', 'scorbunny', 'scovillain', 'scrafty', 'scraggy', 'scream-tail', 'scyther', 'seadra', 'seaking', 'sealeo', 'seedot', 'seel', 'seismitoad', 'sentret', 'serperior', 'servine', 'seviper', 'sewaddle', 'sharpedo', 'shaymin-land', 'shedinja', 'shelgon', 'shellder', 'shellos', 'shelmet', 'shieldon', 'shiftry', 'shiinotic', 'shinx', 'shroodle', 'shroomish', 'shuckle', 'shuppet', 'sigilyph', 'silcoon', 'silicobra', 'silvally', 'simipour', 'simisage', 'simisear', 'sinistea', 'sirfetchd', 'sizzlipede', 'skarmory', 'skeledirge', 'skiddo', 'skiploom', 'skitty', 'skorupi', 'skrelp', 'skuntank', 'skwovet', 'slaking', 'slakoth', 'sliggoo', 'slither-wing', 'slowbro', 'slowking', 'slowpoke', 'slugma', 'slurpuff', 'smeargle', 'smoliv', 'smoochum', 'sneasel', 'sneasler', 'snivy', 'snom', 'snorlax', 'snorunt', 'snover', 'snubbull', 'sobble', 'solgaleo', 'solosis', 'solrock', 'spearow', 'spectrier', 'spewpa', 'spheal', 'spidops', 'spinarak', 'spinda', 'spiritomb', 'spoink', 'sprigatito', 'spritzee', 'squawkabilly-green-plumage', 'squirtle', 'stakataka', 'stantler', 'staraptor', 'staravia', 'starly', 'starmie', 'staryu', 'steelix', 'steenee', 'stonjourner', 'stoutland', 'stufful', 'stunfisk', 'stunky', 'sudowoodo', 'suicune', 'sunflora', 'sunkern', 'surskit', 'swablu', 'swadloon', 'swalot', 'swampert', 'swanna', 'swellow', 'swinub', 'swirlix', 'swoobat', 'sylveon', 'tadbulb', 'taillow', 'talonflame', 'tandemaus', 'tangela', 'tangrowth', 'tapu-bulu', 'tapu-fini', 'tapu-koko', 'tapu-lele', 'tarountula', 'tatsugiri-curly', 'tauros', 'teddiursa', 'tentacool', 'tentacruel', 'tepig', 'terrakion', 'thievul', 'throh', 'thundurus-incarnate', 'thwackey', 'timburr', 'tinkatink', 'tinkaton', 'tinkatuff', 'tirtouga', 'toedscool', 'toedscruel', 'togedemaru', 'togekiss', 'togepi', 'togetic', 'torchic', 'torkoal', 'tornadus-incarnate', 'torracat', 'torterra', 'totodile', 'toucannon', 'toxapex', 'toxel', 'toxicroak', 'toxtricity-amped', 'tranquill', 'trapinch', 'treecko', 'trevenant', 'tropius', 'trubbish', 'trumbeak', 'tsareena', 'turtonator', 'turtwig', 'tympole', 'tynamo', 'type-null', 'typhlosion', 'tyranitar', 'tyrantrum', 'tyrogue', 'tyrunt', 'umbreon', 'unfezant', 'unown', 'ursaluna', 'ursaring', 'urshifu-single-strike', 'uxie', 'vanillish', 'vanillite', 'vanilluxe', 'vaporeon', 'varoom', 'veluza', 'venipede', 'venomoth', 'venonat', 'venusaur', 'vespiquen', 'vibrava', 'victini', 'victreebel', 'vigoroth', 'vikavolt', 'vileplume', 'virizion', 'vivillon', 'volbeat', 'volcanion', 'volcarona', 'voltorb', 'vullaby', 'vulpix', 'wailmer', 'wailord', 'walrein', 'wartortle', 'watchog', 'wattrel', 'weavile', 'weedle', 'weepinbell', 'weezing', 'whimsicott', 'whirlipede', 'whiscash', 'whismur', 'wigglytuff', 'wiglett', 'wimpod', 'wingull', 'wishiwashi-solo', 'wobbuffet', 'woobat', 'wooloo', 'wooper', 'wormadam-plant', 'wugtrio', 'wurmple', 'wynaut', 'wyrdeer', 'xatu', 'xerneas', 'xurkitree', 'yamask', 'yamper', 'yanma', 'yanmega', 'yungoos', 'yveltal', 'zacian', 'zamazenta', 'zangoose', 'zapdos', 'zarude', 'zebstrika', 'zekrom', 'zeraora', 'zigzagoon', 'zoroark', 'zorua', 'zubat', 'zweilous', 'zygarde-50']\n",
      "1000\n",
      "Epoch: 0\n",
      "loss: 6.903933  [   10/20921]\n",
      "loss: 6.928155  [ 1010/20921]\n",
      "loss: 6.632790  [ 2010/20921]\n",
      "loss: 6.810351  [ 3010/20921]\n",
      "loss: 7.301654  [ 4010/20921]\n",
      "loss: 6.519978  [ 5010/20921]\n",
      "loss: 6.301695  [ 6010/20921]\n",
      "loss: 6.524411  [ 7010/20921]\n",
      "loss: 4.553962  [ 8010/20921]\n",
      "loss: 4.057517  [ 9010/20921]\n",
      "loss: 5.627015  [10010/20921]\n",
      "loss: 2.970729  [11010/20921]\n",
      "loss: 3.747487  [12010/20921]\n",
      "loss: 2.504430  [13010/20921]\n",
      "loss: 3.403704  [14010/20921]\n",
      "loss: 2.362876  [15010/20921]\n",
      "loss: 4.883275  [16010/20921]\n",
      "loss: 2.246901  [17010/20921]\n",
      "loss: 0.968430  [18010/20921]\n",
      "loss: 1.547776  [19010/20921]\n",
      "loss: 0.370476  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 1.650592 \n",
      "\n",
      "Epoch: 1\n",
      "loss: 0.242249  [   10/20921]\n",
      "loss: 0.356632  [ 1010/20921]\n",
      "loss: 0.490447  [ 2010/20921]\n",
      "loss: 0.315207  [ 3010/20921]\n",
      "loss: 0.033844  [ 4010/20921]\n",
      "loss: 0.000034  [ 5010/20921]\n",
      "loss: 0.005083  [ 6010/20921]\n",
      "loss: 0.008025  [ 7010/20921]\n",
      "loss: 0.077852  [ 8010/20921]\n",
      "loss: 0.203509  [ 9010/20921]\n",
      "loss: 0.021337  [10010/20921]\n",
      "loss: 0.740411  [11010/20921]\n",
      "loss: 0.056036  [12010/20921]\n",
      "loss: 0.138663  [13010/20921]\n",
      "loss: 0.355327  [14010/20921]\n",
      "loss: 0.272389  [15010/20921]\n",
      "loss: 0.004071  [16010/20921]\n",
      "loss: 0.215397  [17010/20921]\n",
      "loss: 0.444587  [18010/20921]\n",
      "loss: 0.638538  [19010/20921]\n",
      "loss: 0.142096  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 1.171084 \n",
      "\n",
      "Epoch: 2\n",
      "loss: 0.002310  [   10/20921]\n",
      "loss: 0.000009  [ 1010/20921]\n",
      "loss: 0.001319  [ 2010/20921]\n",
      "loss: 0.000039  [ 3010/20921]\n",
      "loss: 0.000047  [ 4010/20921]\n",
      "loss: 0.000131  [ 5010/20921]\n",
      "loss: 0.000020  [ 6010/20921]\n",
      "loss: 0.021609  [ 7010/20921]\n",
      "loss: 0.000006  [ 8010/20921]\n",
      "loss: 0.000051  [ 9010/20921]\n",
      "loss: 0.000553  [10010/20921]\n",
      "loss: 0.000013  [11010/20921]\n",
      "loss: 0.000109  [12010/20921]\n",
      "loss: 0.000001  [13010/20921]\n",
      "loss: 0.000023  [14010/20921]\n",
      "loss: 0.046502  [15010/20921]\n",
      "loss: 0.000618  [16010/20921]\n",
      "loss: 0.000070  [17010/20921]\n",
      "loss: 0.000234  [18010/20921]\n",
      "loss: 0.000000  [19010/20921]\n",
      "loss: 0.000024  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 2.065593 \n",
      "\n",
      "Epoch: 3\n",
      "loss: 0.000002  [   10/20921]\n",
      "loss: 0.002628  [ 1010/20921]\n",
      "loss: 0.000014  [ 2010/20921]\n",
      "loss: 0.001763  [ 3010/20921]\n",
      "loss: 0.137485  [ 4010/20921]\n",
      "loss: 0.004187  [ 5010/20921]\n",
      "loss: 0.001552  [ 6010/20921]\n",
      "loss: 0.000001  [ 7010/20921]\n",
      "loss: 0.000000  [ 8010/20921]\n",
      "loss: 0.000003  [ 9010/20921]\n",
      "loss: 0.001271  [10010/20921]\n",
      "loss: 0.000004  [11010/20921]\n",
      "loss: 0.000003  [12010/20921]\n",
      "loss: 0.068795  [13010/20921]\n",
      "loss: 0.000638  [14010/20921]\n",
      "loss: 0.000171  [15010/20921]\n",
      "loss: 0.000000  [16010/20921]\n",
      "loss: 0.000001  [17010/20921]\n",
      "loss: 0.001086  [18010/20921]\n",
      "loss: 0.000027  [19010/20921]\n",
      "loss: 0.000061  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 2.077114 \n",
      "\n",
      "Epoch: 4\n",
      "loss: 0.049175  [   10/20921]\n",
      "loss: 0.001862  [ 1010/20921]\n",
      "loss: 0.000000  [ 2010/20921]\n",
      "loss: 0.000312  [ 3010/20921]\n",
      "loss: 0.000000  [ 4010/20921]\n",
      "loss: 0.000106  [ 5010/20921]\n",
      "loss: 0.000004  [ 6010/20921]\n",
      "loss: 0.000000  [ 7010/20921]\n",
      "loss: 0.000000  [ 8010/20921]\n",
      "loss: 0.000001  [ 9010/20921]\n",
      "loss: 0.000382  [10010/20921]\n",
      "loss: 0.000008  [11010/20921]\n",
      "loss: 0.000034  [12010/20921]\n",
      "loss: 0.000000  [13010/20921]\n",
      "loss: 0.000088  [14010/20921]\n",
      "loss: 0.000343  [15010/20921]\n",
      "loss: 0.000009  [16010/20921]\n",
      "loss: 0.002192  [17010/20921]\n",
      "loss: 0.000006  [18010/20921]\n",
      "loss: 0.000003  [19010/20921]\n",
      "loss: 0.000194  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 2.592252 \n",
      "\n",
      "Epoch: 5\n",
      "loss: 0.000012  [   10/20921]\n",
      "loss: 0.000001  [ 1010/20921]\n",
      "loss: 0.000004  [ 2010/20921]\n",
      "loss: 0.000000  [ 3010/20921]\n",
      "loss: 0.001123  [ 4010/20921]\n",
      "loss: 0.000000  [ 5010/20921]\n",
      "loss: 0.000000  [ 6010/20921]\n",
      "loss: 0.000000  [ 7010/20921]\n",
      "loss: 0.001441  [ 8010/20921]\n",
      "loss: 0.000000  [ 9010/20921]\n",
      "loss: 0.000000  [10010/20921]\n",
      "loss: 0.000000  [11010/20921]\n",
      "loss: 0.000002  [12010/20921]\n",
      "loss: 0.000410  [13010/20921]\n",
      "loss: 0.000008  [14010/20921]\n",
      "loss: 0.000000  [15010/20921]\n",
      "loss: 0.000000  [16010/20921]\n",
      "loss: 0.006544  [17010/20921]\n",
      "loss: 0.028552  [18010/20921]\n",
      "loss: 0.000035  [19010/20921]\n",
      "loss: 0.000000  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 2.487266 \n",
      "\n",
      "Epoch: 6\n",
      "loss: 0.000000  [   10/20921]\n",
      "loss: 0.000001  [ 1010/20921]\n",
      "loss: 0.000000  [ 2010/20921]\n",
      "loss: 0.000000  [ 3010/20921]\n",
      "loss: 0.000005  [ 4010/20921]\n",
      "loss: 0.000020  [ 5010/20921]\n",
      "loss: 0.000000  [ 6010/20921]\n",
      "loss: 0.000006  [ 7010/20921]\n",
      "loss: 0.000002  [ 8010/20921]\n",
      "loss: 0.000016  [ 9010/20921]\n",
      "loss: 0.004131  [10010/20921]\n",
      "loss: 0.000010  [11010/20921]\n",
      "loss: 0.000001  [12010/20921]\n",
      "loss: 0.000000  [13010/20921]\n",
      "loss: 0.000162  [14010/20921]\n",
      "loss: 0.000032  [15010/20921]\n",
      "loss: 0.000006  [16010/20921]\n",
      "loss: 0.000205  [17010/20921]\n",
      "loss: 0.000003  [18010/20921]\n",
      "loss: 0.000023  [19010/20921]\n",
      "loss: 0.000002  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 2.157588 \n",
      "\n",
      "Epoch: 7\n",
      "loss: 0.000050  [   10/20921]\n",
      "loss: 0.000009  [ 1010/20921]\n",
      "loss: 0.000006  [ 2010/20921]\n",
      "loss: 0.000021  [ 3010/20921]\n",
      "loss: 0.000000  [ 4010/20921]\n",
      "loss: 0.000003  [ 5010/20921]\n",
      "loss: 0.000024  [ 6010/20921]\n",
      "loss: 0.000006  [ 7010/20921]\n",
      "loss: 0.000000  [ 8010/20921]\n",
      "loss: 0.000000  [ 9010/20921]\n",
      "loss: 0.000068  [10010/20921]\n",
      "loss: 0.000000  [11010/20921]\n",
      "loss: 0.000003  [12010/20921]\n",
      "loss: 0.000000  [13010/20921]\n",
      "loss: 0.000000  [14010/20921]\n",
      "loss: 0.000001  [15010/20921]\n",
      "loss: 0.000046  [16010/20921]\n",
      "loss: 0.000000  [17010/20921]\n",
      "loss: 0.000000  [18010/20921]\n",
      "loss: 0.000000  [19010/20921]\n",
      "loss: 0.001173  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 2.767777 \n",
      "\n",
      "Epoch: 8\n",
      "loss: 0.000001  [   10/20921]\n",
      "loss: 0.000000  [ 1010/20921]\n",
      "loss: 0.000000  [ 2010/20921]\n",
      "loss: 0.000000  [ 3010/20921]\n",
      "loss: 0.000000  [ 4010/20921]\n",
      "loss: 0.000000  [ 5010/20921]\n",
      "loss: 0.000000  [ 6010/20921]\n",
      "loss: 0.000000  [ 7010/20921]\n",
      "loss: 0.000001  [ 8010/20921]\n",
      "loss: 0.000000  [ 9010/20921]\n",
      "loss: 0.000008  [10010/20921]\n",
      "loss: 0.000000  [11010/20921]\n",
      "loss: 0.000133  [12010/20921]\n",
      "loss: 0.000002  [13010/20921]\n",
      "loss: 0.000000  [14010/20921]\n",
      "loss: 0.000000  [15010/20921]\n",
      "loss: 0.000000  [16010/20921]\n",
      "loss: 0.000017  [17010/20921]\n",
      "loss: 0.000000  [18010/20921]\n",
      "loss: 0.000155  [19010/20921]\n",
      "loss: 0.000000  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 2.302041 \n",
      "\n",
      "Epoch: 9\n",
      "loss: 0.000780  [   10/20921]\n",
      "loss: 0.000007  [ 1010/20921]\n",
      "loss: 0.000004  [ 2010/20921]\n",
      "loss: 0.000001  [ 3010/20921]\n",
      "loss: 0.000043  [ 4010/20921]\n",
      "loss: 0.000790  [ 5010/20921]\n",
      "loss: 0.000036  [ 6010/20921]\n",
      "loss: 0.000002  [ 7010/20921]\n",
      "loss: 0.000000  [ 8010/20921]\n",
      "loss: 0.000000  [ 9010/20921]\n",
      "loss: 0.000000  [10010/20921]\n",
      "loss: 0.000020  [11010/20921]\n",
      "loss: 0.000092  [12010/20921]\n",
      "loss: 0.000001  [13010/20921]\n",
      "loss: 0.000000  [14010/20921]\n",
      "loss: 0.000030  [15010/20921]\n",
      "loss: 0.000012  [16010/20921]\n",
      "loss: 0.000013  [17010/20921]\n",
      "loss: 0.000000  [18010/20921]\n",
      "loss: 0.000024  [19010/20921]\n",
      "loss: 0.000000  [20010/20921]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 2.379560 \n",
      "\n",
      "Entrenament finalitzat.\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2D_MaxPool2D = nn.Sequential(\n",
    "            nn.Conv2d(3, 30, (5, 5), stride=2),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.Conv2d(30, 60, (2, 2), stride=3),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(60, 120, (5, 5), stride=2),\n",
    "            nn.MaxPool2d((1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(38880, 1000),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2D_MaxPool2D(x)\n",
    "        return x\n",
    "\n",
    "    #Shapes de les x conforme passa per les capes\n",
    "    \"\"\" \n",
    "    class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Definir cada capa individualmente\n",
    "        self.conv1 = nn.Conv2d(3, 30, (5,5), stride=2, padding=2)\n",
    "        self.maxpool1 = nn.MaxPool2d((1,1))\n",
    "        self.conv2 = nn.Conv2d(30, 60, (2,2), stride=3)\n",
    "        self.maxpool2 = nn.MaxPool2d((1,1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(60, 120, (5,5), stride=4)\n",
    "        self.maxpool3 = nn.MaxPool2d((1,1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(12000, 1000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Paso por cada capa y imprimir las salidas entre las capas\n",
    "        print(f'Input shape: {x.shape}')\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        print(f'After conv1: {x.shape}')  # Tamaño después de la convolución 1\n",
    "\n",
    "        x = self.maxpool1(x)\n",
    "        print(f'After maxpool1: {x.shape}')  # Tamaño después del max pooling 1\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        print(f'After conv2: {x.shape}')  # Tamaño después de la convolución 2\n",
    "\n",
    "        x = self.maxpool2(x)\n",
    "        print(f'After maxpool2: {x.shape}')  # Tamaño después del max pooling 2\n",
    "\n",
    "        x = self.relu1(x)\n",
    "        print(f'After relu1: {x.shape}')  # Tamaño después de ReLU 1\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        print(f'After conv3: {x.shape}')  # Tamaño después de la convolución 3\n",
    "\n",
    "        x = self.maxpool3(x)\n",
    "        print(f'After maxpool3: {x.shape}')  # Tamaño después de max pooling 3\n",
    "\n",
    "        x = self.relu2(x)\n",
    "        print(f'After relu2: {x.shape}')  # Tamaño después de ReLU 2\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        print(f'After flatten: {x.shape}')  # Tamaño después de aplanar la imagen\n",
    "\n",
    "        x = self.fc(x)\n",
    "        print(f'After fc (linear): {x.shape}')  # Tamaño después de la capa lineal\n",
    "\n",
    "        return x\n",
    "    \"\"\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((244, 244)), # Redimensionar a 200x200p\n",
    "    transforms.ToTensor(), # Convertir imatges a tensors de PyTorch\n",
    "])\n",
    "\n",
    "data_path = '/home/itibcn/Desktop/Torch/datasets/pokemondataset/train'\n",
    "data_path2 = '/home/itibcn/Desktop/Torch/datasets/pokemondataset/test'\n",
    "\n",
    "train = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "test = datasets.ImageFolder(root=data_path2, transform = transform)\n",
    "\n",
    "dataloader_train = DataLoader(train, batch_size=10, shuffle=True)\n",
    "dataloader_test = DataLoader(test, batch_size=10, shuffle=True)\n",
    "\n",
    "output_dimension = len(datasets.ImageFolder(root=data_path).classes)\n",
    "bs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "\n",
    "#Inicialitzar el model, funcio de perdua i optimitzador\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Mostrar las clases\n",
    "print(f\"Clases del dataset: {train.classes}\")\n",
    "print(len(train.classes))\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, bs):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * bs + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)    \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    train_loop(dataloader_train, model, loss, optimizer, bs)\n",
    "    test_loop(dataloader_test, model, loss)\n",
    "\n",
    "    #epoch_loss = running_loss / len(train)\n",
    "    #epoch_accuracy = 100 * correct / total\n",
    "    #print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "    \n",
    "print('Entrenament finalitzat.')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model_path = '/home/itibcn/Desktop/Torch/modelPokimon38880.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 115\u001b[0m\n\u001b[1;32m    112\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    114\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m--> 115\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0005\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Mostrar las clases\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClases del dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torch/optim/adam.py:78\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     67\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     68\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     fused\u001b[38;5;241m=\u001b[39mfused,\n\u001b[1;32m     77\u001b[0m )\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/Desktop/Torch/entornoVirtualPytorch/lib/python3.10/site-packages/torch/optim/optimizer.py:366\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    364\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    368\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "class NN_model(nn.Module):\n",
    "    def init(self):\n",
    "        super().init()\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "\n",
    "            # nn.Conv2d(in_channels=3,out_channels=64, kernel_size=5, stride=3), \n",
    "            # nn.MaxPool2d(3), \n",
    "            # nn.LeakyReLU(0.1),\n",
    "            # nn.Conv2d(64, 128, 3, stride=2), \n",
    "            # # nn.MaxPool2d(2), \n",
    "            # # nn.ReLU(),\n",
    "            # nn.Conv2d(128, 128, 3), \n",
    "            # nn.MaxPool2d(2), \n",
    "            # nn.LeakyReLU(0.1),\n",
    "            # nn.Conv2d(128, 300, 3),\n",
    "            # #nn.MaxPool2d(2), \n",
    "            # #nn.ReLU(),\n",
    "            # #nn.Conv2d(300, 300, 3), \n",
    "            # #nn.LeakyReLU(0.1),\n",
    "\n",
    "nn.Flatten(),\n",
    "            resnet18(ResNet18_Weights), \n",
    "            # nn.Linear(1200 , 10000),\n",
    "            # nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000 , 5000),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(5000 , 1000),\n",
    "\n",
    "\n",
    "        )\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2D_MaxPool2D(x)\n",
    "        return x\n",
    "\n",
    "    #Shapes de les x conforme passa per les capes\n",
    "    \"\"\" \n",
    "    class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Definir cada capa individualmente\n",
    "        self.conv1 = nn.Conv2d(3, 30, (5,5), stride=2, padding=2)\n",
    "        self.maxpool1 = nn.MaxPool2d((1,1))\n",
    "        self.conv2 = nn.Conv2d(30, 60, (2,2), stride=3)\n",
    "        self.maxpool2 = nn.MaxPool2d((1,1))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(60, 120, (5,5), stride=4)\n",
    "        self.maxpool3 = nn.MaxPool2d((1,1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(12000, 1000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Paso por cada capa y imprimir las salidas entre las capas\n",
    "        print(f'Input shape: {x.shape}')\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        print(f'After conv1: {x.shape}')  # Tamaño después de la convolución 1\n",
    "\n",
    "        x = self.maxpool1(x)\n",
    "        print(f'After maxpool1: {x.shape}')  # Tamaño después del max pooling 1\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        print(f'After conv2: {x.shape}')  # Tamaño después de la convolución 2\n",
    "\n",
    "        x = self.maxpool2(x)\n",
    "        print(f'After maxpool2: {x.shape}')  # Tamaño después del max pooling 2\n",
    "\n",
    "        x = self.relu1(x)\n",
    "        print(f'After relu1: {x.shape}')  # Tamaño después de ReLU 1\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        print(f'After conv3: {x.shape}')  # Tamaño después de la convolución 3\n",
    "\n",
    "        x = self.maxpool3(x)\n",
    "        print(f'After maxpool3: {x.shape}')  # Tamaño después de max pooling 3\n",
    "\n",
    "        x = self.relu2(x)\n",
    "        print(f'After relu2: {x.shape}')  # Tamaño después de ReLU 2\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        print(f'After flatten: {x.shape}')  # Tamaño después de aplanar la imagen\n",
    "\n",
    "        x = self.fc(x)\n",
    "        print(f'After fc (linear): {x.shape}')  # Tamaño después de la capa lineal\n",
    "\n",
    "        return x\n",
    "    \"\"\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((244, 244)), # Redimensionar a 200x200p\n",
    "    transforms.ToTensor(), # Convertir imatges a tensors de PyTorch\n",
    "])\n",
    "\n",
    "data_path = '/home/itibcn/Desktop/Torch/datasets/pokemondataset/train'\n",
    "data_path2 = '/home/itibcn/Desktop/Torch/datasets/pokemondataset/test'\n",
    "\n",
    "train = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "test = datasets.ImageFolder(root=data_path2, transform = transform)\n",
    "\n",
    "dataloader_train = DataLoader(train, batch_size=10, shuffle=True)\n",
    "dataloader_test = DataLoader(test, batch_size=10, shuffle=True)\n",
    "\n",
    "output_dimension = len(datasets.ImageFolder(root=data_path).classes)\n",
    "bs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 100\n",
    "\n",
    "#Inicialitzar el model, funcio de perdua i optimitzador\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Mostrar las clases\n",
    "print(f\"Clases del dataset: {train.classes}\")\n",
    "print(len(train.classes))\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, bs):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * bs + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)    \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    train_loop(dataloader_train, model, loss, optimizer, bs)\n",
    "    test_loop(dataloader_test, model, loss)\n",
    "\n",
    "    #epoch_loss = running_loss / len(train)\n",
    "    #epoch_accuracy = 100 * correct / total\n",
    "    #print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "    \n",
    "print('Entrenament finalitzat.')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model_path = '/home/itibcn/Desktop/Torch/modelPokimon.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornoVirtualPytorch",
   "language": "python",
   "name": "entornovirtualpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
